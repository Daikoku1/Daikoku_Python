{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter1. 신경망\n",
    "====\n",
    "### 1.1 수학과 파이썬 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "W = np.array([[1, 2, 3], \n",
    "              [4, 5, 6]])\n",
    "X = np.array([[0, 1, 2], \n",
    "              [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5],\n",
       "       [ 7,  9, 11]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  6],\n",
       "       [12, 20, 30]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise(point-wise)\n",
    "W * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20],\n",
       "       [30, 40]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2], \n",
    "              [3, 4]])\n",
    "\n",
    "A * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 40],\n",
       "       [30, 80]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2], \n",
    "              [3, 4]])\n",
    "b = np.array([10, 20])\n",
    "\n",
    "A * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터의 내적\n",
    "- $\\mathbf{x} = (x_1, \\dots, x_n)$, $\\mathbf{y} = (y_1, \\dots, y_n)$ 에 대하여, 백터의 내적은 두 벡터에서 대응하는 원소들의 곱을 모두 더한 것\n",
    "    $$\n",
    "\\mathbf{x} \\cdot \\mathbf{y} = \\mathbf{x}^{T} \\mathbf{y} = x_1y_1 + x_2y_2 + \\cdots + x_ny_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터의 내적\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬의 곱\n",
    "A = np.array([[1, 2], \n",
    "              [3, 4]])\n",
    "B = np.array([[5, 6], \n",
    "              [7, 8]])\n",
    "\n",
    "np.matmul(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 신경망 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpur -> hidden\n",
    "W1 = np.random.randn(2, 4)  # 가중치\n",
    "b1 = np.random.randn(4)\n",
    "x = np.random.randn(10, 2)\n",
    "h = np.matmul(x, W1) + b1  # b1 은 브로드캐스팅 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32252584,  0.39630236,  0.87746871,  2.08688293],\n",
       "       [ 1.28048016,  1.46781086,  1.05987576,  1.25152984],\n",
       "       [ 2.19520373,  0.90683189,  1.21129518, -1.43136482],\n",
       "       [ 1.44273029,  2.305136  ,  1.10019143,  1.89054768],\n",
       "       [ 0.28652034,  0.98473617,  0.87964412,  2.8664906 ],\n",
       "       [ 0.44932949,  1.65183802,  0.91761201,  3.30169794],\n",
       "       [ 0.03228135, -2.10361694,  0.79095479, -0.2487576 ],\n",
       "       [ 2.19878991,  2.58477235,  1.23602389,  0.55761285],\n",
       "       [ 1.47838752,  2.96643725,  1.11590764,  2.59898843],\n",
       "       [ 0.67521401, -1.1717835 ,  0.91643284, -0.55629026]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57993969, 0.59779894, 0.7062974 , 0.88962172],\n",
       "       [0.7825315 , 0.81272442, 0.7426668 , 0.77756457],\n",
       "       [0.89981798, 0.71235143, 0.77052804, 0.19288612],\n",
       "       [0.8088771 , 0.90930151, 0.75029597, 0.86881796],\n",
       "       [0.57114404, 0.72804696, 0.70674847, 0.94616487],\n",
       "       [0.6104798 , 0.83913931, 0.71455529, 0.96448701],\n",
       "       [0.50806964, 0.10874577, 0.68803631, 0.43812932],\n",
       "       [0.90014079, 0.9298751 , 0.77487116, 0.63590002],\n",
       "       [0.8143289 , 0.95103463, 0.75322884, 0.93079645],\n",
       "       [0.66266968, 0.23653276, 0.71431472, 0.36440626]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sigmoid(h)  # 활성화(activation)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45205347, -2.15724574, -0.43151579],\n",
       "       [-0.15394501, -2.57704987, -0.73517741],\n",
       "       [ 1.17077949, -2.15835009, -1.16100808],\n",
       "       [-0.36533225, -2.80481378, -0.72611997],\n",
       "       [-0.70688643, -2.40503284, -0.39805934],\n",
       "       [-0.79419005, -2.62641842, -0.43980207],\n",
       "       [ 0.73105732, -1.04187035, -0.54945961],\n",
       "       [ 0.18457095, -2.76529502, -0.95300733],\n",
       "       [-0.50343272, -2.91182817, -0.70435701],\n",
       "       [ 0.97640391, -1.30671483, -0.77375747]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden -> output\n",
    "W2 = np.random.randn(4, 3)\n",
    "b2 = np.random.randn(3)\n",
    "\n",
    "s = np.matmul(a, W2) + b2  # score 값\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드(Sigmoid) 레이어 구현\n",
    "class Sigmoid:\n",
    "    '''Sigmoid Layer class\n",
    "    \n",
    "    Sigmoid layer에는 학습하는 params가 따로 없으므로 \n",
    "    인스턴스 변수인 params는 빈 리스트로 초기화\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"순전파(forward propagation) 메서드\n",
    "        Args:\n",
    "            x(ndarray): 입력으로 들어오는 값\n",
    "        Returns:\n",
    "            Sigmoid 활성화 값\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전연결계층(Affine) 구현\n",
    "class Affine:\n",
    "    '''FC layer'''\n",
    "    def __init__(self, W, b):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            W(ndarray): 가중치(weight)\n",
    "            b(ndarray): 편향(bias)\n",
    "        \"\"\"\n",
    "        self.params = [W, b]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"순전파(forward propagation) 메서드\n",
    "        Args:\n",
    "            x(ndarray): 입력으로 들어오는 값\n",
    "        Returns:\n",
    "            out(ndarray): Wx + b\n",
    "        \"\"\"\n",
    "        W, b = self.params\n",
    "        out = np.matmul(x, W) + b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "        # 가중치와 편향 초기화\n",
    "        # input -> hidden\n",
    "        W1 = np.random.randn(I, H)  \n",
    "        b1 = np.random.randn(H)\n",
    "         # hidden -> output\n",
    "        W2 = np.random.randn(H, O) \n",
    "        b2 = np.random.randn(O)\n",
    "        \n",
    "        # 레이어 생성\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "        # 모든 가중치를 리스트에 모은다.\n",
    "        self.parmas = [layer.params for layer in self.layers]\n",
    "        # self.params = []\n",
    "        # for layer in self.layers:\n",
    "        #     self.params += layer.params\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 2)\n",
    "model = TwoLayerNet(2, 4, 3)\n",
    "s = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.24747399, -2.13935735,  0.41854382],\n",
       "       [-2.00206159, -2.15990205,  0.38258516],\n",
       "       [-2.42973118, -3.31998456, -0.32856543],\n",
       "       [-1.77611146, -1.96541305,  0.4040273 ],\n",
       "       [-2.11082283, -2.28744723,  0.34541667],\n",
       "       [-2.00345416, -2.27525013,  0.33360981],\n",
       "       [-2.32356771, -2.4952179 ,  0.24778931],\n",
       "       [-1.35765624, -2.60006665, -0.02934648],\n",
       "       [-1.30931871, -2.80577934, -0.2073413 ],\n",
       "       [-1.26268666, -1.70854025,  0.37410496]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 신경망 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (1, 8)\n",
      "y.shape: (7, 8)\n"
     ]
    }
   ],
   "source": [
    "# Repeat 노드 예제\n",
    "\n",
    "D, N = 8, 7\n",
    "x = np.random.randn(1, D)  # 입력\n",
    "# np.repeat()이 복제노드 역할을 함\n",
    "y = np.repeat(x, N, axis=0)  # 순전파\n",
    "\n",
    "print(f'x.shape: {x.shape}')\n",
    "print(f'y.shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953],\n",
       "       [ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953],\n",
       "       [ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953],\n",
       "       [ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953],\n",
       "       [ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953],\n",
       "       [ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953],\n",
       "       [ 0.12884531,  0.36058465, -0.70570528,  1.34323151, -0.06046834,\n",
       "         0.35621279, -0.2311544 , -0.82609953]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = np.random.randn(N, D)  # 랜덤한 기울기\n",
    "# keepdims=True -> 차원수 유지\n",
    "dx = np.sum(dy, axis=0, keepdims=True)  # 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (7, 8)\n",
      "y.shape: (1, 8)\n"
     ]
    }
   ],
   "source": [
    "# Sum 노드 역전파 예제\n",
    "\n",
    "D, N = 8, 7\n",
    "x = np.random.randn(N, D)  # 입력\n",
    "y = np.sum(x, axis=0, keepdims=True)  # 순전파\n",
    "\n",
    "print(f'x.shape: {x.shape}')\n",
    "print(f'y.shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = np.random.randn(1, D)  # 랜덤한 기울기 생성\n",
    "dx = np.repeat(dy, N, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.02253303, -0.43988526, -0.26428666, -0.9610439 ,  0.3894802 ,\n",
       "        -0.48280064,  0.40698727,  1.83965076],\n",
       "       [-1.02253303, -0.43988526, -0.26428666, -0.9610439 ,  0.3894802 ,\n",
       "        -0.48280064,  0.40698727,  1.83965076],\n",
       "       [-1.02253303, -0.43988526, -0.26428666, -0.9610439 ,  0.3894802 ,\n",
       "        -0.48280064,  0.40698727,  1.83965076],\n",
       "       [-1.02253303, -0.43988526, -0.26428666, -0.9610439 ,  0.3894802 ,\n",
       "        -0.48280064,  0.40698727,  1.83965076],\n",
       "       [-1.02253303, -0.43988526, -0.26428666, -0.9610439 ,  0.3894802 ,\n",
       "        -0.48280064,  0.40698727,  1.83965076],\n",
       "       [-1.02253303, -0.43988526, -0.26428666, -0.9610439 ,  0.3894802 ,\n",
       "        -0.48280064,  0.40698727,  1.83965076],\n",
       "       [-1.02253303, -0.43988526, -0.26428666, -0.9610439 ,  0.3894802 ,\n",
       "        -0.48280064,  0.40698727,  1.83965076]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MatMul 클래스 구현\n",
    "# common/layers.py\n",
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.matmul(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.matmul(dout, W.T)\n",
    "        dW = np.matmul(self.x.T, dout)\n",
    "        self.grads[0][...] = dW  # 깊은 복사\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얕은 복사와 깊은 복사 차이 확인\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a) == id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[...] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a) == id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid layer 클래스 구현\n",
    "# common/layers.py\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.matmul(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.matmul(dout, W.T)\n",
    "        dW = np.matmul(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel42/project/Python_Study/밑바닥/Ch01-NeuralNetworksReview'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common.functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6e9bf8f7573e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/aiffel42/project/Python_Study/밑바닥'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 부모 디렉터리의 파일을 가져올 수 있도록 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSoftmaxWithLoss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common.functions'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aiffel42/project/Python_Study/밑바닥')  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.y = None  # softmax의 출력\n",
    "        self.t = None  # 정답 레이블\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "\n",
    "        # 정답 레이블이 원핫 벡터일 경우 정답의 인덱스로 변환\n",
    "        # cross_entropy_error()에 이미 있어서 굳이 필요 없을 듯\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t. argmax(axis=1)\n",
    "\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx /= batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    '''\n",
    "    확률적 경사하강법(SGD, Stochastic Gradient Descent)\n",
    "        W <- W - lr * (dL/dW)\n",
    "    '''\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr  # learning rate\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 신경망으로 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import spiral\n",
    "\n",
    "x, t = spiral.load_data()\n",
    "print('x', x.shape)  # (300, 2)\n",
    "print('t', t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터점 플롯\n",
    "N = 100\n",
    "CLS_NUM = 3\n",
    "markers = ['o', 'x', '^']\n",
    "for i in range(CLS_NUM):\n",
    "    plt.scatter(x[i*N:(i+1)*N, 0], x[i*N:(i+1)*N, 1], s=40, marker=markers[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch01/two_layer_net.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from common.layers import Affine, Sigmoid, SoftmaxWithLoss\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "        \n",
    "        # 가중치와 편향 초기화\n",
    "        W1 = 0.01 * np.random.randn(I, H)\n",
    "        b1 = np.zeros(H)\n",
    "        W2 = 0.01 * np.random.randn(H, O)\n",
    "        b2 = np.zeros(O)\n",
    "        \n",
    "        # 레이어 생성\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        score = self.predict(x)\n",
    "        loss = self.loss_layer.forward(score, t)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch01/train_custom_loop.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # pip install tqdm\n",
    "from common.optimizer import SGD\n",
    "from dataset import spiral\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "matplotlib.rc('font', family='Malgun Gothic')  # linux\n",
    "# matplotlib.rc('font', family='AppleGothic')  # Mac\n",
    "\n",
    "# 1. 하이퍼파라미터 설정\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "learning_rate = 1.0\n",
    "\n",
    "# 2. 데이터 읽기, 모델과 옵티마이저 생성\n",
    "x, t = spiral.load_data()\n",
    "model = TwoLayerNet(input_size=2,\n",
    "                    hidden_size=hidden_size,\n",
    "                    output_size=3)\n",
    "optimizer = SGD(lr=learning_rate)\n",
    "\n",
    "# 학습에 사용하는 변수\n",
    "data_size = len(x)\n",
    "max_iters = data_size // batch_size\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "loss_list = []\n",
    "\n",
    "for epoch in tqdm(range(max_epoch)):\n",
    "    # 3. 데이터 셔플링\n",
    "    idx = np.random.permutation(data_size)\n",
    "    x = x[idx]\n",
    "    t = t[idx]\n",
    "    \n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "        \n",
    "        # 기울기를 구해 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "        # 정기적으로 학습 경과 출력\n",
    "        if (iters+1) % 10 == 0:\n",
    "            avg_loss = total_loss / loss_count\n",
    "            print(f'| 에폭 {epoch+1} | 반복{iters+1}/{max_iters} | 손실 {avg_loss:.2f}')\n",
    "            loss_list.append(avg_loss)\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
