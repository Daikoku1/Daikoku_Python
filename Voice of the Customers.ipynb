{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    " - 사용자 리뷰가 정보를 제공하는 좋은 소스가 됨\n",
    " - 기존프로그램 : 품질에 기반한 랭킹 제공\n",
    " - 그러나 물건들은 각기 다른 방면에서 쓸모가 있음 --> 전반적인 품질로는 모든 사용자의 니즈를 만족시킬 수 없음\n",
    " - 기능 기반 랭킹 / 고객리뷰기반  \n",
    "   \n",
    "     1. 리뷰분석\n",
    "     2. 리뷰의 어조 분석(긍정/ 부정)\n",
    "     3. 모델링(가중치를 사용한 제품 간 관계도 그래프)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    " - 고객리뷰\n",
    "     - 판매자리뷰에 비해 정직\n",
    "     - 사용방법, \n",
    "     - 장래구매자에게 영향력 높음(by comScore and Kelsey group)\n",
    "     - But Too much 리뷰 / 개인이 모든 리뷰를 읽고 판단하기에 무리\n",
    " - Product Features\n",
    "     - 데이터 전처리 단계에서 추출하여 결정\n",
    "     - 대부분의 product에서 중요하게 생각되는 feature들은 제공됨\n",
    "     - 각각의 문자에 해당하는 feature들을 라벨링한다.\n",
    "     - Rank를 결정하는데 유용한 문장(리뷰의)들을 4가지 타입으로 분류한다.\n",
    "     - 가중치를 구하고, 그래프를 그린다.\n",
    " - Subjective sentence  \n",
    "     - 리뷰어가 물건에 대해 긍정 / 부정 적인 시각을 내보이는 것\n",
    " - Comparative sentence\n",
    "     - 비교대상 물품과의 비교에 대한 정보가 들어있는 것\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Work\n",
    " - opinion mining, sentence sentiment classification과 연관됨\n",
    "     - opinion mining : 웹사이트와 소셜미디어에 나타난 여론과 의견을 분석하여 유용한 정보로 재가공 하는 기술.\n",
    " - 특징\n",
    "     1. 키워드매칭전략(keyword matching strategy)\n",
    "     2. sentiment 방향성을 설정하기 위한 전략 & 제품간 비교 통합\n",
    "     3. 문장 분류에 기반하여, 물건의 각각의 기능에 대한 그래프를 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Ranking Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Identifying Product Features\n",
    " - 수집된 product feature : Digital Cameras, Television\n",
    "     - at official consumer reports\n",
    " - 동의어(synonyms)는 대다수의 사용자가 product feature을 묘사하는데 사용하는 단어가 다르기 때문에 사용함\n",
    " - 효율 평가 방법\n",
    "     1. 랜덤으로 1000개의 리뷰문장을 선택\n",
    "     2. 라벨링( by 설명된 product  feature)  \n",
    "     = precision : 검색 결과 중에 실제로 '관계되는' 문서가 몇 개인가를 의미  \n",
    "     = recall : 검색어와 관계되는 문서 전체 중에 몇 개를 찾아내느냐  \n",
    "     = 논문 결과 : precision = 0.853, recall = 0.807\n",
    " - 논문 데이터셋\n",
    "     - 1516001 문장\n",
    "     - 약 16%가 1개 이상의 product feature을 묘사함\n",
    "#### 태깅 방법\n",
    " - product feature가 있는 경우 ==> feature 묘사로 마킹\n",
    " - product feature 상세(필요하면 찾자)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Sentence Labeling\n",
    " - 고객의견은 다양한 방법으로 표현됨\n",
    " - 유용한 text 종류는 2가지(Subjective, Comparative)\n",
    " - MxTerminator\n",
    "     - 사용하여 리뷰를 각각의 문장으로 분리\n",
    "     - 전형적인 리뷰들은 몇개의 문장으로 구분되기 때문에.  \n",
    "     \n",
    "## Definition\n",
    "### Subjective Sentence(SS)\n",
    " - 직접적인 긍정/부정 표현\n",
    "     - ex) 카메라 셔터 스피드가 빠름\n",
    "     \n",
    "### Comparative Sentence(CS)\n",
    " - 간접적인 표현 by 비교질\n",
    "     - ex) A보다 B가 더 나은 듯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Identifying Comparative Sentences\n",
    " - keyword comparison, sentence semantic, sentence structure 사용\n",
    "     - KW contains 126 words\n",
    "         - 명백한 표현 (“outperform, exceed,compare, superior, etc.”) \n",
    "         - 함축적인 표현 (“prefer,choose, like, etc.”))\n",
    " - CRFTagger를 사용하여 품사태깅\n",
    " - 룰\n",
    "     1. KW 안의 keywords가 문장에 들어있는지 확인\n",
    "     2. JJR, RBR, JJS, RBS 의 품사에 해당하는 단어 인식\n",
    "     3. 문장에 사전 정의 된 구조 패턴이 있는지 확인\n",
    "        - as <word> as, the same as, similar to, etc.\n",
    "     4. 룰을 만족한다고 모두 Comparative Sentence가 아님\n",
    " - 최소 한개 이상의 비교물품 이름이 포함된 문장만을 CS로 사용\n",
    "     - ex) 아들이 더 높은 점수를 받아서 카메라를 샀어요 와 같은 문장을 처리하기 위해\n",
    " - 논문상 precision 82% , recall 80%\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Idetifying Sentence Sentiment Orientation\n",
    " - 긍정 / 부정 만을 구별\n",
    " - positive word set(POS) / negative word set(NEG) 사용\n",
    "     - MQPA project에서 발전\n",
    "     - POS : 1974, NEG : 4605\n",
    " - 문장에 POS 포함 --> 긍정 라벨링\n",
    " - 부정의 경우 고객들은 애매하게 표현 --> 28개의 부정단어셋을 추가\n",
    " - precision 82%, recall 86%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Constructing the Product Graph\n",
    " - Gf = (V, E)\n",
    "     - V : set of nodes\n",
    "     - E : set of edges\n",
    " - Comparative (Pi 리뷰에서 Pj가 비교대상으로 등장)\n",
    "     - Pi 와 Pj 사이에 edge추가\n",
    "     - 해당 edge에 가중치(weight) 부여\n",
    "         - 가중치 값 : PC / NC\n",
    "     - Pi 리뷰인데, Pj보다 좋다는 리뷰이면 긍정적비교로 간주\n",
    "         - 긍정시 : PC(Pi, Pj)\n",
    "         - 부정시 : NC(Pi, Pj)\n",
    " - Subjective\n",
    "     - 가중치(weight) : PS /NS\n",
    "         - PS : number of positive\n",
    "         - NS : number of negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Ranking Products\n",
    " - 전통적인 PageRank 알고리즘\n",
    "     - 모든 edge를 똑같이 취급\n",
    "     - node weight 고려 X\n",
    " - pRank(논문 알고리즘)\n",
    "     - relative importance값만이 아니라 importance/quality를 사용\n",
    "     - node weight도 ranking에 많은 영향을 준다는 의미\n",
    " - pRank(P) = [(1-d) + d * sum[1, n]( 1 * pRank(Pi) * Ce(Pi)] * Cv(P)\n",
    "     - pRank(P) : product ranking of product P\n",
    "     - pRank(Pi) : P와 edge로 연결된 다른 물건들의 ranking\n",
    "     - Ce(Pi) = We(Pi,P) / sum[1, m](We(Pi,Pj)\n",
    "         - m : number of links on Pi with many P's\n",
    "     - Cv(P) = Wv(P,P) / sum[1, n](Wv(Pt,Pt)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experiment Results \n",
    " - overall quality 기반 랭킹 계산\n",
    "     - Subjective + Comparative in 데이타베이스 -> 그래프\n",
    "     - product feature에 대한 필터링 없음\n",
    " - 효율성 평가\n",
    "     - domain experts 방식으로 만들어진 Ranking과 비교\n",
    "     - overall == 62% \n",
    " - feature 방식\n",
    "     - overall 방식과 비교하여 드라마틱한 변화는 없었음\n",
    "     - 고객이 관심을 기능 집합을 선택한 경우 이 목록의 최상위 제품은 전체 목록에서 순위가 나쁘면 안됨\n",
    "     - But 순위 순서, 특히 상단에 중요한 차이가 가능성이 크다\n",
    "     - 제품 기능의 상대적 중요성\n",
    "         - 고객의 선택에 따라 랭킹 정의\n",
    "         - RFFf = Nf / sum(Nf) * 100\n",
    "             - Nf : number of sentences labeled feature f\n",
    "         - IFf = |X & Yf| / |X|\n",
    "             - & : 교집합\n",
    "             - X : top 10% of overall ranked products\n",
    "             - Yf : top 10% of products by feature f\n",
    "         - 높은 언급횟수(RFFf)가 높은 중요도(IFf)를 나타내지 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion  \n",
    "1. 각각의 product에 대해 고객들이 관심 있어하는 feature들을 결정\n",
    "2. Subjective, Comparative 문장들을 정의하여 텍스트마이닝에 사용\n",
    "3. 2번 문장들을 사용하여 특정 기능의 상대비교를 반영하는 그래프 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
